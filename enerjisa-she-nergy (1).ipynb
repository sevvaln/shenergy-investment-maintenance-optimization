{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13697570,"sourceType":"datasetVersion","datasetId":8712924}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install xlsxwriter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:36:30.968322Z","iopub.execute_input":"2025-11-19T17:36:30.968564Z","iopub.status.idle":"2025-11-19T17:36:34.831520Z","shell.execute_reply.started":"2025-11-19T17:36:30.968522Z","shell.execute_reply":"2025-11-19T17:36:34.830497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**KARAR AÄACI KODU**","metadata":{}},{"cell_type":"code","source":"# -- coding: utf-8 --\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport os\nimport re\n\n# ========== DOSYA YOLU ==========\nPATH = \"/kaggle/input/vggkjgj/2024_BAKENT_TABLO-1 SHENERGY ALIMA.xlsx\"\n\n# ========= YardÄ±mcÄ±: normalize =========\nTR_MAP = str.maketrans({\n    \"Ä°\":\"i\",\"I\":\"i\",\"Ä±\":\"i\",\"ÅŸ\":\"s\",\"Å\":\"s\",\"ÄŸ\":\"g\",\"Ä\":\"g\",\n    \"Ã¼\":\"u\",\"Ãœ\":\"u\",\"Ã¶\":\"o\",\"Ã–\":\"o\",\"Ã§\":\"c\",\"Ã‡\":\"c\"\n})\ndef normalize(s: str) -> str:\n    s = str(s)\n    s = s.translate(TR_MAP).lower()\n    s = re.sub(r\"[^a-z0-9]+\",\" \", s).strip()\n    return s\n\n# ========= Header bulma =========\ndef looks_like_header(row):\n    vals = [str(x) for x in row.tolist()]\n    keys = [\"cbs\",\"kod\",\"unsur\",\"yuk\",\"fider\",\"trafo\",\"neden\",\"tip\",\"tarih\",\"sure\",\"sonuc\",\"asset\",\"yatirim\"]\n    text_ratio = sum(normalize(v)!='' for v in vals)/max(1,len(vals))\n    hit = any(any(k in normalize(v) for k in keys) for v in vals)\n    return text_ratio>0.3 and hit\n\nraw = pd.read_excel(PATH, header=None)\nheader_row = 0\nfor i in range(min(25, len(raw))):\n    if looks_like_header(raw.iloc[i]):\n        header_row = i\n        break\n\ndf = pd.read_excel(PATH, header=header_row)\ndf.columns = df.columns.map(lambda x: str(x).strip())\n\n# ========= AkÄ±llÄ± kolon bulucu =========\ndef find_col_by_tokens(token_sets, prefer=None):\n    norm_cols = [(c, normalize(c)) for c in df.columns]\n    for tokens in token_sets:\n        toks = [normalize(t) for t in tokens]\n        for c, nc in norm_cols:\n            if all(t in nc for t in toks):\n                return c\n    if prefer:\n        pnorm = normalize(prefer)\n        for c,nc in norm_cols:\n            if pnorm in nc:\n                return c\n    return None\n\ndef pick_code_column():\n    cands = [['cbs','kod'],['asset','id'],['unsur','kod'],['kod']]\n    return find_col_by_tokens(cands)\n\nCODE_COL = pick_code_column()\nif CODE_COL is None:\n    raise ValueError(\"CBS/Asset kodu sÃ¼tunu bulunamadÄ±.\")\n\nCOL_TRAF_FIDER = find_col_by_tokens([['trafo','fider'], ['trafo'], ['fider']])\nCOL_TIP_DETAY  = find_col_by_tokens([['sebeke','unsuru','tipi'], ['unsur','tipi'], ['3c']])\nCOL_YUK        = find_col_by_tokens([['yuzdelik','yuk','profil'], ['yuk','profil'], ['yuk','%']], prefer=\"yuk\")\nCOL_NEDEN      = find_col_by_tokens([['nedenine','iliskin','aciklama'], ['aciklama'], ['neden']])\nCOL_SURE       = find_col_by_tokens([['kesinti','suresi'], ['saat']])\n\n# ========= SayÄ±/Tarih dÃ¶nÃ¼ÅŸtÃ¼rme =========\ndef to_float(x):\n    \"\"\"%92, 92%, ' 92 ', '0.92' gibi deÄŸerleri doÄŸru parse eder.\"\"\"\n    try:\n        s = str(x).strip().replace(\",\", \".\")\n        s = re.sub(r\"[^0-9.]+\", \"\", s)\n        if s == \"\": return np.nan\n        v = float(s)\n        return v*100 if v <= 1.5 else v\n    except:\n        return np.nan\n\ndef parse_date_or_year(x):\n    \"\"\"ISO (YYYY-mm-dd[ HH:MM:SS]) iÃ§in dayfirst=False; TR (dd.mm.yyyy[ HH:MM:SS]) iÃ§in dayfirst=True.\"\"\"\n    if pd.isna(x):\n        return pd.NaT\n    s = str(x).strip()\n\n    # ISO-like\n    if re.match(r\"^\\d{4}-\\d{2}-\\d{2}(?:[ T]\\d{2}:\\d{2}:\\d{2})?$\", s):\n        return pd.to_datetime(s, dayfirst=False, errors=\"coerce\")\n\n    # dd.mm.yyyy ...\n    if re.match(r\"^\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}(?:\\s+\\d{1,2}:\\d{2}:\\d{2})?$\", s):\n        dt = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n        if not pd.isna(dt): return dt\n\n    # Genel temizlik\n    s_clean = re.sub(r\"[^\\d\\.\\-:\\s]\", \"\", s)\n    dt = pd.to_datetime(s_clean, dayfirst=True, errors=\"coerce\")\n    if not pd.isna(dt): return dt\n\n    # YalnÄ±z yÄ±l\n    yr = pd.to_numeric(s, errors=\"coerce\")\n    if not pd.isna(yr):\n        try:\n            return datetime(int(yr), 1, 1)\n        except:\n            return pd.NaT\n\n    return pd.NaT\n\n# ========= Ã–zelleÅŸtirme tarihi (post) iÃ§in yardÄ±mcÄ±lar =========\nPRIV_CUTOFF_DT = datetime(2009, 1, 28)          # post==True eÅŸiÄŸi\nPRE2008_CUTOFF = datetime(2008, 1, 28)          # istersen kullanÄ±rsÄ±n (yÃ¼k>80 iÃ§in farklÄ± eÅŸik gerekiyorsa)\n\n# YalnÄ±zca bu tip kolonlar \"Ã¶zelleÅŸtirme\" sayÄ±lÄ±r:\nPRIV_DATE_KEYWORDS = [\n    (\"ozellestirme\",\"tarihi\"),\n    (\"ozellestirme\",),\n    (\"devralma\",\"tarihi\"),\n    (\"kesin\",\"kabul\",\"tarihi\"),\n    (\"isletmeye\",\"alis\",\"tarihi\"),\n    (\"tesis\",\"devreye\",\"tarihi\"),\n]\n\n# Bunlar hariÃ§ tutulur:\nEXCLUDE_DATE_PATTERNS = [\n    \"baslang\", \"bitis\", \"bildirim\", \"ariza\", \"saat\", \"sure\", \"dakika\",\n    \"kesinti\", \"olay\", \"start\", \"end\"\n]\n\ndef pick_priv_date_columns(frame: pd.DataFrame):\n    cols = []\n    norm_cols = [(c, normalize(c)) for c in frame.columns]\n    for keys in PRIV_DATE_KEYWORDS:\n        toks = [normalize(k) for k in keys]\n        for c, nc in norm_cols:\n            if all(t in nc for t in toks):\n                cols.append(c)\n    return cols\n\ndef get_priv_date(sub: pd.DataFrame):\n    \"\"\"Ã–zelleÅŸtirme/devralma/kesin kabul/iÅŸletmeye alÄ±ÅŸ/tesis devreye kolonlarÄ±ndan (EXCLUDE hariÃ§)\n       tarihleri topla ve en erkenini dÃ¶ndÃ¼r. Yoksa None.\"\"\"\n    cols = [c for c in pick_priv_date_columns(sub)\n            if not any(b in normalize(c) for b in EXCLUDE_DATE_PATTERNS)]\n    if not cols:\n        return None\n\n    dts = []\n    for c in cols:\n        dts.extend(sub[c].apply(parse_date_or_year).dropna().tolist())\n    if not dts:\n        return None\n\n    ser = pd.to_datetime(pd.Series(dts).dt.normalize(), errors=\"coerce\").dropna()\n    if ser.empty:\n        return None\n    return ser.min()\n\ndef post_cutoff_by_dates(sub):\n    \"\"\"True => 28.01.2009 ve sonrasÄ±, False => Ã¶ncesi, None => tarih yok.\n       (Sadece 'Ã¶zelleÅŸtirme' sÄ±nÄ±fÄ±ndaki kolonlara bakar, EXCLUDE edilenleri dÄ±ÅŸlar.)\"\"\"\n    dt_min = get_priv_date(sub)\n    if dt_min is None:\n        return None\n    return bool(dt_min >= PRIV_CUTOFF_DT)\n\n# ========= Tip tespiti =========\ndef describe_type(sub):\n    vals = []\n    for col in [COL_TRAF_FIDER, COL_TIP_DETAY]:\n        if col and col in sub.columns:\n            vals += sub[col].dropna().astype(str).tolist()\n    n = normalize(\" \".join(vals))\n    if 'fider' in n: return \"FÄ°DER\"\n    if 'traf' in n: return \"TRAFO\"\n    colnames = \" \".join(normalize(c) for c in df.columns)\n    if 'fider' in colnames: return \"FÄ°DER\"\n    if 'traf' in colnames: return \"TRAFO\"\n    code_hint = str(sub[CODE_COL].iloc[0]).upper() if not sub.empty else \"\"\n    if re.search(r\"(TR|TF|TRAFO)\", code_hint): return \"TRAFO\"\n    return \"TRAFO\"\n\n# ========= YatÄ±rÄ±m planÄ± var mÄ±? =========\ndef detect_yatirim_gorus_column():\n    candidates = []\n    for c in df.columns:\n        nc = normalize(c)\n        if any(k in nc for k in [\"yatirim\",\"gorus\"]) and not any(k in nc for k in [\"sonuc\",\"karar\",\"decision\",\"result\"]):\n            candidates.append(c)\n    def score(series):\n        s = series.astype(str).str.upper()\n        return s.str.contains(r\"\\bVAR\\b|\\bYOK\\b\").mean()\n    best = None; best_score = -1\n    for c in candidates:\n        sc = score(df[c])\n        if sc > best_score: best, best_score = c, sc\n    return best\n\nCOL_YATIRIM_GOR = detect_yatirim_gorus_column()\n\ndef yatirim_plani_var_mi(sub):\n    if not COL_YATIRIM_GOR or COL_YATIRIM_GOR not in sub.columns:\n        return None\n    vals = sub[COL_YATIRIM_GOR].astype(str).str.upper().replace({\"TRUE\":\"VAR\",\"FALSE\":\"YOK\",\"1\":\"VAR\",\"0\":\"YOK\"})\n    if vals.str.contains(r\"\\bVAR\\b\").any(): return True\n    if vals.str.contains(r\"\\bYOK\\b\").any(): return False\n    return None\n\n# ===================================== KARAR AÄACI =====================================\n# --- Ä°mal yÄ±lÄ± kolonlarÄ±nÄ± bul (yardÄ±mcÄ±) ---\nIMAL_DATE_KEYWORDS = [\n    (\"imal\",\"yili\"), (\"imal\",\"yil\"), (\"imal\",), (\"uretim\",\"yili\")\n]\ndef pick_imal_date_columns(frame: pd.DataFrame):\n    cols = []\n    norm_cols = [(c, normalize(c)) for c in frame.columns]\n    for keys in IMAL_DATE_KEYWORDS:\n        toks = [normalize(k) for k in keys]\n        for c, nc in norm_cols:\n            if all(t in nc for t in toks):\n                cols.append(c)\n    return cols\n\ndef get_imal_date(sub: pd.DataFrame):\n    cols = pick_imal_date_columns(sub)\n    if not cols: return None\n    dts = []\n    for c in cols:\n        if c in sub.columns:\n            dts.extend(sub[c].apply(parse_date_or_year).dropna().tolist())\n    if not dts: return None\n    ser = pd.to_datetime(pd.Series(dts).dt.normalize(), errors=\"coerce\").dropna()\n    if ser.empty: return None\n    try:\n        m = ser.mode()\n        return m.iloc[0] if not m.empty else ser.median()\n    except Exception:\n        return ser.max()\n\n# --- (opsiyonel) gri kutu: bakÄ±m projesi ile Ã§Ã¶zÃ¼lebilir mi?\ndef bakim_projesiyle_cozulebilir_mi(sub) -> bool:\n    if COL_NEDEN and COL_NEDEN in sub.columns:\n        txt = \" \".join(sub[COL_NEDEN].dropna().astype(str).str.lower().tolist())\n        for p in [\"bakÄ±m projesi\",\"bakim projesi\",\"iletken\",\"sehim\",\"aÄŸaÃ§\",\"agac\",\"dÄ±ÅŸ etken\",\"dis etken\",\"sigorta\",\"ÅŸalter\",\"salter\"]:\n            if p in txt: return True\n    return False\n\n\n# ============================== KARAR AÄACI (7 NET YOL) ==============================\n\ndef karar_agaci(sub: pd.DataFrame, code_str: str) -> str:\n    \"\"\"\n    7 temel karar yolu:\n      1) YÃ¼k > 80  &  (Ã¶zelleÅŸtirme/imal) < 28.01.2009               -> YATIRIM\n      2) YÃ¼k > 80  &  (Ã¶zelleÅŸtirme/imal) >= 28.01.2009              -> OPERASYON\n      3) YÃ¼k â‰¤ 80 &  TRAFO & (Ã¶zelleÅŸtirme/imal) < 28.01.2009 & YP=VAR  -> YATIRIM\n      4) YÃ¼k â‰¤ 80 &  TRAFO & (Ã¶zelleÅŸtirme/imal) < 28.01.2009 & YP=YOK  -> BAKIM\n      5) YÃ¼k â‰¤ 80 &  TRAFO & (Ã¶zelleÅŸtirme/imal) >= 28.01.2009          -> OPERASYON\n      6) YÃ¼k â‰¤ 80 &  FÄ°DER & YP=VAR                                     -> YATIRIM\n      7) YÃ¼k â‰¤ 80 &  FÄ°DER & YP=YOK                                     -> BAKIM\n    \"\"\"\n\n    # --- â¿¡ YÃ¼k ortalamasÄ±nÄ± bul ---\n    avg_load = None\n    if COL_YUK and COL_YUK in sub.columns:\n        ser = sub[COL_YUK].apply(to_float)\n        if ser.notna().any():\n            avg_load = ser.mean()\n\n    # --- â¿¢ Tip (TRAFO/FÄ°DER), tarih, yatÄ±rÄ±m planÄ± ---\n    tip       = describe_type(sub)                 # \"TRAFO\" / \"FÄ°DER\" / belirsiz\n    post      = post_cutoff_by_dates(sub)          # True: >= 28.01.2009, False: < 28.01.2009, None: yok\n    imal_dt   = get_imal_date(sub)                 # None olabilir\n    imal_post = None if imal_dt is None else bool(imal_dt >= PRIV_CUTOFF_DT)\n    eff_post  = post if post is not None else imal_post  # Ã¶zell. yoksa imal yÄ±lÄ±na dÃ¼ÅŸ\n    yp        = yatirim_plani_var_mi(sub)          # True / False / None\n\n    # --- â¿£ Karar yollarÄ± ---\n    # [1] ve [2] YÃ¼k > 80\n    if avg_load is not None and avg_load > 80:\n        if eff_post is False:   # < 28.01.2009\n            return \"YATIRIM\"\n        if eff_post is True:    # â‰¥ 28.01.2009\n            return \"OPERASYON\"\n        return \"YATIRIM\"        # tarih bilinmiyor â†’ temkinli yatÄ±rÄ±m\n\n    # [3]â€“[7] YÃ¼k â‰¤ 80 (veya yÃ¼k bilinmiyor)\n    if tip == \"TRAFO\":\n        if eff_post is False:\n            if yp is True:  return \"YATIRIM\"  # [3]\n            if yp is False: return \"BAKIM\"    # [4]\n            return \"BAKIM\"\n        if eff_post is True:\n            return \"OPERASYON\"                # [5]\n        return \"BAKIM\"\n\n    if tip == \"FÄ°DER\":\n        if yp is True:  return \"YATIRIM\"      # [6]\n        if yp is False: return \"BAKIM\"        # [7]\n        return \"BAKIM\"\n\n    # Tip belirsiz: trafoya benzer davran, temkinli\n    if eff_post is True:  return \"OPERASYON\"\n    if eff_post is False: return \"YATIRIM\" if yp else \"BAKIM\"\n    return \"BAKIM\"\n\n\n\n# ========= Ã–ZET =========\ndef summarize_one_code(code_str):\n    code_str = str(code_str).strip().upper()\n    sub = df[df[CODE_COL].astype(str).str.upper() == code_str]\n    if sub.empty:\n        return {\"CBS Kodu\": code_str, \"Karar\": \"BulunamadÄ±\"}\n    tip = describe_type(sub)\n    kesinti_sayisi = len(sub)\n    total_hours = sub[COL_SURE].apply(to_float).sum() if COL_SURE in sub.columns else np.nan\n    avg_load = np.nan\n    if COL_YUK in sub.columns:\n        al = sub[COL_YUK].apply(to_float)\n        if al.notna().any(): avg_load = al.mean()\n    karar = karar_agaci(sub, code_str)\n    neden_map = {}\n    if COL_NEDEN in sub.columns:\n        counts = sub[COL_NEDEN].dropna().astype(str).value_counts()\n        neden_map = {k:int(v) for k,v in counts.items()}\n    return {\"CBS Kodu\": code_str, \"Åebeke Unsuru Tipi\": tip, \"Kesinti SayÄ±sÄ±\": int(kesinti_sayisi),\n            \"Toplam SÃ¼re\": float(total_hours) if not pd.isna(total_hours) else np.nan,\n            \"Ortalama YÃ¼k\": float(avg_load) if not pd.isna(avg_load) else np.nan,\n            \"Karar\": karar, \"Neden FrekanslarÄ±\": neden_map}\n\ndef print_pretty(summary):\n    print(f\"\\n--- {summary['CBS Kodu']} ---\")\n    print(f\"Tip: {summary.get('Åebeke Unsuru Tipi')}\")\n    print(f\"Kesinti: {summary.get('Kesinti SayÄ±sÄ±')}\")\n    print(f\"Ortalama YÃ¼k: {summary.get('Ortalama YÃ¼k')}\")\n    print(f\"Karar: {summary.get('Karar')}\")\n    nf = summary.get(\"Neden FrekanslarÄ±\")\n    if nf:\n        print(\"Nedenler:\")\n        for k,v in nf.items(): print(f\"  â€¢ {k}: {v}\")\n\n# ========= Ã‡ALIÅTIRMA =========\n\nif __name__ == \"__main__\":\n    codes = [c.strip() for c in input(\"CBS kod(lar)Ä±nÄ± gir: \").split(\",\") if c.strip()]\n    results = [summarize_one_code(c) for c in codes]\n    for r in results: print_pretty(r)\n    out = \"/content/cbs_batch_summary.xlsx\"\n    pd.DataFrame(results).to_excel(out, index=False)\n    print(f\"\\nğŸ“¦ SonuÃ§ kaydedildiÂ â†’Â {out}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:25:43.519357Z","iopub.execute_input":"2025-12-15T08:25:43.519671Z","iopub.status.idle":"2025-12-15T08:25:55.965157Z","shell.execute_reply.started":"2025-12-15T08:25:43.519649Z","shell.execute_reply":"2025-12-15T08:25:55.964429Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"CBS kod(lar)Ä±nÄ± gir:  TAT551TR1P1C\n"},{"name":"stdout","text":"\n--- TAT551TR1P1C ---\nTip: FÄ°DER\nKesinti: 19\nOrtalama YÃ¼k: 11.038000000000002\nKarar: YATIRIM\nNedenler:\n  â€¢ Olumsuz Hava Sartlari - Sigorta ArÄ±za: 7\n  â€¢ Bakim Ihtiyaci - Sigorta ArÄ±za: 6\n  â€¢ Agac ve Dis Etkenler - Sigorta ArÄ±za: 3\n  â€¢ -Ekonomik Ã–mÃ¼r - Sigorta ArÄ±za: 2\n  â€¢ Asiri Yuk - Sigorta ArÄ±za: 1\n\nğŸ“¦ SonuÃ§ kaydedildiÂ â†’Â /content/cbs_batch_summary.xlsx\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**ARAYÃœZ KODU**","metadata":{}},{"cell_type":"code","source":"!pip install gradio pandas numpy openpyxl plotly --quiet\n\nimport gradio as gr\nimport pandas as pd\nimport numpy as np\nimport re\nfrom datetime import datetime\nimport plotly.express as px\n\n# ================== GENEL YARDIMCI FONKSÄ°YONLAR ==================\nTR_MAP = str.maketrans({\n    \"Ä°\": \"i\", \"I\": \"i\", \"Ä±\": \"i\",\n    \"Å\": \"s\", \"ÅŸ\": \"s\",\n    \"Ä\": \"g\", \"ÄŸ\": \"g\",\n    \"Ãœ\": \"u\", \"Ã¼\": \"u\",\n    \"Ã–\": \"o\", \"Ã¶\": \"o\",\n    \"Ã‡\": \"c\", \"Ã§\": \"c\",\n})\n\ndef norm_header(s: str) -> str:\n    s = str(s)\n    s = s.translate(TR_MAP).lower()\n    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n    return s.strip()\n\ndef clean_str(x):\n    \"\"\"\n    GÃ¶rÃ¼nen metinler iÃ§in: TÃ¼rkÃ§e karakterleri BOZMADAN\n    sadece boÅŸluk/tire temizliÄŸi ve basit formatlama yap.\n    \"\"\"\n    if x is None or (isinstance(x, float) and np.isnan(x)):\n        return \"\"\n    s = str(x).replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n\n    # Birden fazla boÅŸluk -> tek boÅŸluk\n    s = re.sub(r\"\\s+\", \" \", s)\n    s = s.replace(\"â€“\", \"-\").replace(\"â€”\", \"-\")\n    s = s.replace(\" - \", \"-\").replace(\"- \", \"-\").replace(\" -\", \"-\")\n\n    # Ä°lk harf bÃ¼yÃ¼k, kalan kÃ¼Ã§Ã¼k (Ã¶zellikle ÅŸehir / ilÃ§e iÃ§in)\n    if len(s) > 0:\n        s = s[0].upper() + s[1:].lower()\n\n    return s.strip()\n\ndef to_float(x):\n    if x is None or (isinstance(x, float) and np.isnan(x)):\n        return np.nan\n    s = str(x).replace(\",\", \".\")\n    s = re.sub(r\"[^0-9.]\", \"\", s)\n    if s == \"\":\n        return np.nan\n    try:\n        return float(s)\n    except:\n        return np.nan\n\ndef parse_date(x):\n    if x is None or (isinstance(x, float) and np.isnan(x)):\n        return None\n    try:\n        return pd.to_datetime(x, dayfirst=True, errors=\"coerce\")\n    except Exception:\n        return None\n\ndef find_column(df, token_sets, fallback=None):\n    headers = list(df.columns)\n    norms = [norm_header(h) for h in headers]\n\n    for tokens in token_sets:\n        toks = [norm_header(t) for t in tokens]\n        for col, nh in zip(headers, norms):\n            if all(t in nh for t in toks):\n                return col\n\n    if fallback is not None:\n        fb = norm_header(fallback)\n        for col, nh in zip(headers, norms):\n            if fb == nh:\n                return col\n    return None\n\ndef load_to_percent(val):\n    \"\"\"\n    Excel'deki yÃ¼zdelik yÃ¼k:\n    - 0 < x < 2  ise: 0.85 -> 85.0 (%)\n    - 2 <= x <= 100 ise: olduÄŸu gibi (%)\n    \"\"\"\n    v = to_float(val)\n    if np.isnan(v):\n        return np.nan\n    if 0 < v < 2:\n        v = v * 100.0\n    return v\n\n# ================== TÃœRKÄ°YE Ä°L â†’ KOORD SÃ–ZLÃœÄÃœ ==================\n# (TÃ¼m iller duruyor, ama senin veri ÅŸu an KÄ±rÄ±kkale & Zonguldak bÃ¶lgesinden.)\nTURKEY_CITIES = {\n    \"adana\": (37.0, 35.3),\n    \"adiyaman\": (37.8, 38.3),\n    \"afyonkarahisar\": (38.8, 30.5),\n    \"agri\": (39.7, 43.0),\n    \"amasya\": (40.6, 35.8),\n    \"ankara\": (39.9, 32.9),\n    \"antalya\": (36.9, 30.7),\n    \"artvin\": (41.2, 41.8),\n    \"aydin\": (37.8, 27.8),\n    \"balikesir\": (39.6, 27.9),\n    \"bilecik\": (40.1, 29.9),\n    \"bingol\": (38.9, 40.5),\n    \"bitlis\": (38.4, 42.1),\n    \"bolu\": (40.7, 31.6),\n    \"burdur\": (37.7, 30.3),\n    \"bursa\": (40.2, 29.0),\n    \"canakkale\": (40.1, 26.4),\n    \"cankiri\": (40.6, 33.6),\n    \"corum\": (40.5, 34.9),\n    \"denizli\": (37.8, 29.1),\n    \"diyarbakir\": (37.9, 40.2),\n    \"edirne\": (41.7, 26.6),\n    \"elazig\": (38.7, 39.2),\n    \"erzincan\": (39.7, 39.5),\n    \"erzurum\": (39.9, 41.3),\n    \"eskisehir\": (39.8, 30.5),\n    \"gaziantep\": (37.1, 37.4),\n    \"giresun\": (40.9, 38.4),\n    \"gumushane\": (40.5, 39.5),\n    \"hakkari\": (37.6, 43.7),\n    \"hatay\": (36.2, 36.1),\n    \"isparta\": (37.8, 30.5),\n    \"mersin\": (36.8, 34.6),\n    \"istanbul\": (41.0, 28.9),\n    \"izmir\": (38.4, 27.1),\n    \"kars\": (40.6, 43.1),\n    \"kastamonu\": (41.4, 33.8),\n    \"kayseri\": (38.7, 35.5),\n    \"kirklareli\": (41.7, 27.2),\n    \"kirsehir\": (39.1, 34.2),\n    \"kocaeli\": (40.8, 29.9),\n    \"konya\": (37.9, 32.5),\n    \"kutahya\": (39.4, 29.9),\n    \"malatya\": (38.3, 38.3),\n    \"manisa\": (38.6, 27.4),\n    \"kahramanmaras\": (37.6, 36.9),\n    \"mardin\": (37.3, 40.7),\n    \"mugla\": (37.2, 28.4),\n    \"mus\": (38.7, 41.5),\n    \"nevsehir\": (38.6, 34.7),\n    \"nigde\": (37.9, 34.7),\n    \"ordu\": (40.9, 37.9),\n    \"rize\": (41.0, 40.5),\n    \"sakarya\": (40.8, 30.4),\n    \"samsun\": (41.3, 36.3),\n    \"siirt\": (37.9, 41.9),\n    \"sinop\": (42.0, 35.1),\n    \"sivas\": (39.7, 37.0),\n    \"tekirdag\": (40.9, 27.5),\n    \"tokat\": (40.3, 36.6),\n    \"trabzon\": (41.0, 39.7),\n    \"tunceli\": (39.1, 39.5),\n    \"sanliurfa\": (37.2, 38.8),\n    \"usak\": (38.7, 29.4),\n    \"van\": (38.5, 43.4),\n    \"yozgat\": (39.8, 34.8),\n    \"zonguldak\": (41.4535, 31.7890),\n    \"aksaray\": (38.4, 34.0),\n    \"bayburt\": (40.3, 40.2),\n    \"karaman\": (37.2, 33.2),\n    \"kirikkale\": (39.8468, 33.5153),\n    \"batman\": (37.9, 41.1),\n    \"sirnak\": (37.5, 42.5),\n    \"bartin\": (41.6, 32.3),\n    \"ardahan\": (41.1, 42.7),\n    \"igdir\": (39.9, 44.0),\n    \"yalova\": (40.6, 29.3),\n    \"karabuk\": (41.2, 32.6),\n    \"kilis\": (36.7, 37.1),\n    \"osmaniye\": (37.1, 36.2),\n    \"duzce\": (40.8, 31.2),\n}\n\n# ================== KARAR AÄACI (7 YOL) ==================\ndef karar_agaci(avg_load, tip, tarih, yatirim_plani_var):\n    cutoff = datetime(2009, 1, 28)\n    eff_post = None\n    if tarih is not None:\n        eff_post = tarih >= cutoff\n\n    if avg_load is not None and avg_load > 80:\n        if eff_post is False:\n            return \"YATIRIM\"\n        if eff_post is True:\n            return \"OPERASYON\"\n        return \"YATIRIM\"\n\n    if tip == \"TRAFO\":\n        if eff_post is False:\n            if yatirim_plani_var is True:\n                return \"YATIRIM\"\n            if yatirim_plani_var is False:\n                return \"BAKIM\"\n            return \"BAKIM\"\n        if eff_post is True:\n            return \"OPERASYON\"\n        return \"BAKIM\"\n\n    if tip == \"FÄ°DER\":\n        if yatirim_plani_var is True:\n            return \"YATIRIM\"\n        if yatirim_plani_var is False:\n            return \"BAKIM\"\n        return \"BAKIM\"\n\n    if eff_post is True:\n        return \"OPERASYON\"\n    if eff_post is False:\n        return \"YATIRIM\" if yatirim_plani_var else \"BAKIM\"\n    return \"BAKIM\"\n\ndef karar_badge_html(karar: str) -> str:\n    if karar == \"YATIRIM\":\n        bg = \"linear-gradient(135deg,#2dd4bf,#22c1c3)\"\n    elif karar == \"OPERASYON\":\n        bg = \"linear-gradient(135deg,#60a5fa,#3b82f6)\"\n    else:\n        bg = \"linear-gradient(135deg,#facc15,#f97316)\"\n\n    return f\"\"\"\n<div style=\"\n    display:inline-block;\n    padding:10px 18px;\n    border-radius:999px;\n    background:{bg};\n    color:#020617;\n    font-weight:700;\n    box-shadow:0 0 18px rgba(120,200,255,0.55);\n\">\n    Karar: {karar}\n</div>\n\"\"\"\n\n# ================== GLOBAL GEÃ‡MÄ°Å ==================\nHISTORY_CODES = []\n\n# ================== ANA ANALÄ°Z ==================\ndef analyze_file(file, cbs_code):\n    if file is None:\n        return (\"LÃ¼tfen Excel dosyasÄ±nÄ± yÃ¼kleyin.\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n\n    try:\n        df = pd.read_excel(file.name)\n    except Exception as e:\n        return (f\"Dosya okunamadÄ±: {e}\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n\n    # kolon bulma\n    COL_CBS   = find_column(df, [[\"cbs\",\"kodu\"],[\"cbs\",\"kod\"],[\"cbs\"]])\n    COL_IL    = find_column(df, [[\"il\",\"3a\"],[\"il \"]])\n    COL_ILCE  = find_column(df, [[\"ilce\",\"3b\"],[\"ilce\"]])\n    COL_NEDEN = find_column(df, [[\"kesinti\",\"nedenine\",\"iliskin\",\"aciklama\"],[\"kesinti\",\"nedeni\"]])\n    COL_BAS   = find_column(df, [[\"kesinti\",\"baslama\",\"tarihi\"],[\"baslama\",\"tarih\"]])\n    COL_BIT   = find_column(df, [[\"kesinti\",\"sona\",\"erme\",\"tarihi\"],[\"bitis\",\"tarih\"]])\n    COL_SURE  = find_column(df, [[\"kesinti\",\"suresi\",\"saat\"],[\"kesinti\",\"suresi\"]])\n    COL_YUK   = find_column(df, [[\"yuzdelik\",\"yuk\",\"profil\"],[\"yuk\",\"profil\"],[\"yuk\",\"%\"]])\n    COL_TIP   = find_column(df, [[\"trafo\",\"fider\"],[\"trafo\"],[\"fider\"]])\n    COL_YP    = find_column(df, [[\"yatirim\",\"gorusu\"],[\"yatirim\",\"gÃ¶rÃ¼ÅŸÃ¼\"]])\n    COL_IMAL  = find_column(df, [[\"imal\",\"yili\"],[\"uretim\",\"yili\"]])\n\n    if COL_CBS is None:\n        return (\"Excel'de CBS kodu kolonu bulunamadÄ± (Ã¶rn. 'CBS KODU').\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n\n    code = clean_str(cbs_code).upper()\n    if not code:\n        return (\"LÃ¼tfen CBS kodu girin.\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n\n    sub = df[df[COL_CBS].astype(str).str.upper().str.strip() == code]\n\n    if sub.empty:\n        if code not in HISTORY_CODES:\n            HISTORY_CODES.append(code)\n        hist_md = \"### ğŸ” GeÃ§miÅŸ Aramalar\\n\" + \", \".join(HISTORY_CODES)\n        return (f\"{code}** iÃ§in kayÄ±t bulunamadÄ±.\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, hist_md, HISTORY_CODES)\n\n    # metrikler\n    kesinti_sayisi = len(sub)\n\n    total_hours_ser = sub[COL_SURE].apply(to_float) if COL_SURE else pd.Series([np.nan])\n    total_hours = total_hours_ser.sum() if total_hours_ser.notna().any() else 0\n\n    # YÃ¼k: 0â€“2 arasÄ± ise *100, 2â€“100 arasÄ± ise direkt\n    if COL_YUK:\n        loads = sub[COL_YUK].apply(load_to_percent)\n        avg_load = loads.mean() if loads.notna().any() else None\n    else:\n        loads = pd.Series([np.nan])\n        avg_load = None\n\n    tip_raw = clean_str(sub[COL_TIP].iloc[0]) if COL_TIP else \"\"\n    tip_low = tip_raw.lower()\n    tip = \"TRAFO\" if \"traf\" in tip_low else \"FÄ°DER\"\n\n    dts = sub[COL_BAS].apply(parse_date).dropna() if COL_BAS else pd.Series([], dtype=\"datetime64[ns]\")\n    first_dt = dts.min() if not dts.empty else None\n\n    imal_dt = None\n    if COL_IMAL and COL_IMAL in sub.columns:\n        raw_imal = sub[COL_IMAL].iloc[0]\n        if not pd.isna(raw_imal):\n            try:\n                y = int(str(raw_imal)[:4])\n                imal_dt = datetime(y, 1, 1)\n            except:\n                imal_dt = None\n\n    eff_date = first_dt or imal_dt\n\n    yp_val = None\n    if COL_YP and COL_YP in sub.columns:\n        vals = sub[COL_YP].astype(str).str.upper()\n        if (vals.str.contains(\"VAR\")).any():\n            yp_val = True\n        elif (vals.str.contains(\"YOK\")).any():\n            yp_val = False\n\n    karar = karar_agaci(avg_load, tip, eff_date, yp_val)\n\n    il   = clean_str(sub[COL_IL].iloc[0])   if COL_IL   else \"-\"\n    ilce = clean_str(sub[COL_ILCE].iloc[0]) if COL_ILCE else \"-\"\n\n    # neden frekanslarÄ±\n    nf_dict = {}\n    if COL_NEDEN:\n        neden_ser = sub[COL_NEDEN]\n        for v in neden_ser:\n            if pd.isna(v):\n                continue\n            clean_v = clean_str(v)\n            if clean_v == \"\":\n                continue\n            nf_dict[clean_v] = nf_dict.get(clean_v, 0) + 1\n\n    # kayÄ±tlar\n    kayitlar = []\n    for _, row in sub.iterrows():\n        rec = {\n            \"BaÅŸlangÄ±Ã§\": parse_date(row[COL_BAS]) if COL_BAS else None,\n            \"BitiÅŸ\": parse_date(row[COL_BIT]) if COL_BIT else None,\n            \"SÃ¼re (saat)\": to_float(row[COL_SURE]) if COL_SURE else np.nan,\n            \"Neden\": clean_str(row[COL_NEDEN]) if COL_NEDEN else \"\",\n            \"YÃ¼k (%)\": load_to_percent(row[COL_YUK]) if COL_YUK else np.nan,\n            \"Ä°l\": clean_str(row[COL_IL]) if COL_IL else \"\",\n            \"Ä°lÃ§e\": clean_str(row[COL_ILCE]) if COL_ILCE else \"\",\n        }\n        kayitlar.append(rec)\n    detay_df = pd.DataFrame(kayitlar)\n\n    # karar kartÄ±\n    badge_html = karar_badge_html(karar)\n    card_md = f\"\"\"\n### ğŸ“¦ CBS Kodu: *{code}*\n\n{badge_html}\n\n<br/>\n\n- Åebeke Unsuru: *{tip}*\n- Kesinti SayÄ±sÄ±: *{kesinti_sayisi}*\n- Toplam SÃ¼re (saat): *{round(total_hours,2)}*\n- Ortalama YÃ¼k (%): *{round(avg_load,1) if avg_load is not None else \"-\"}*\n\"\"\"\n\n    # ek bilgiler + Ã¶zet\n    if eff_date is not None:\n        year_min = eff_date.year\n        year_max = (sub[COL_BAS].apply(parse_date).dropna().max().year\n                    if COL_BAS and sub[COL_BAS].notna().any() else year_min)\n        year_span = f\"{year_min}-{year_max}\" if year_min != year_max else str(year_min)\n    else:\n        year_span = \"-\"\n\n    summary_sentence = (\n        f\"Bu CBS kodunda {year_span} dÃ¶neminde toplam {kesinti_sayisi} kesinti kaydÄ± bulunmuÅŸtur. \"\n        f\"Toplam kesinti sÃ¼resi yaklaÅŸÄ±k {round(total_hours,2)} saattir ve \"\n        f\"ortalama yÃ¼k yaklaÅŸÄ±k %{round(avg_load,1) if avg_load is not None else 0} seviyesindedir.\"\n    )\n\n    ek_md = f\"\"\"\n### ğŸ—‚ Ek Bilgiler\n\n- Ä°l: *{il}*\n- Ä°lÃ§e: *{ilce}*\n- KayÄ±tlÄ± kesinti sayÄ±sÄ±: *{kesinti_sayisi}*\n- DÃ¶nem: *{year_span}*\n\n*Ã–zet:* {summary_sentence}\n\"\"\"\n\n    # neden frekanslarÄ± md\n    if nf_dict:\n        nf_lines = \"\\n\".join([f\"- *{k}*: {v} kez\" for k, v in nf_dict.items()])\n        nf_md = \"### âš¡ Kesinti Nedenleri (Frekans)\\n\\n\" + nf_lines\n    else:\n        nf_md = \"### âš¡ Kesinti Nedenleri\\n\\nKayÄ±tlÄ± neden bulunamadÄ±.\"\n\n    explanation_md = \"\"\n\n    # grafikler\n    fig_years = None\n    if not detay_df.empty and detay_df[\"BaÅŸlangÄ±Ã§\"].notna().any():\n        years = pd.to_datetime(detay_df[\"BaÅŸlangÄ±Ã§\"]).dt.year.dropna()\n        year_counts = years.value_counts().sort_index()\n        fig_years = px.bar(\n            x=year_counts.index.astype(str),\n            y=year_counts.values,\n            labels={\"x\": \"YÄ±l\", \"y\": \"Kesinti SayÄ±sÄ±\"},\n            title=\"YÄ±llara GÃ¶re Kesinti SayÄ±sÄ±\"\n        )\n        fig_years.update_layout(\n            template=\"plotly_dark\",\n            paper_bgcolor=\"rgba(0,0,0,0)\",\n            plot_bgcolor=\"rgba(0,0,0,0)\",\n            font_color=\"#e5edff\"\n        )\n\n    fig_reasons = None\n    if nf_dict:\n        r_df = pd.DataFrame({\"Neden\": list(nf_dict.keys()), \"SayÄ±\": list(nf_dict.values())})\n        fig_reasons = px.bar(\n            r_df, x=\"Neden\", y=\"SayÄ±\",\n            title=\"Kesinti Nedenlerinin DaÄŸÄ±lÄ±mÄ±\"\n        )\n        fig_reasons.update_layout(\n            template=\"plotly_dark\",\n            paper_bgcolor=\"rgba(0,0,0,0)\",\n            plot_bgcolor=\"rgba(0,0,0,0)\",\n            font_color=\"#e5edff\"\n        )\n\n    # Kesinti SÃ¼resi DaÄŸÄ±lÄ±mÄ± GRAFÄ°ÄÄ° TAMAMEN KALDIRILDI\n\n    fig_location = None\n    if il != \"-\" and il:\n        key = norm_header(il)\n        if key in TURKEY_CITIES:\n            lat, lon = TURKEY_CITIES[key]\n            loc_df = pd.DataFrame({\"lat\": [lat], \"lon\": [lon], \"Ä°l\": [il], \"Ä°lÃ§e\": [ilce]})\n            fig_location = px.scatter_geo(\n                loc_df,\n                lat=\"lat\", lon=\"lon\",\n                hover_name=\"Ä°lÃ§e\",\n                text=\"Ä°l\",\n                scope=\"asia\",\n                title=\"Lokasyon (TÃ¼rkiye Ãœzerinde YaklaÅŸÄ±k Konum)\"\n            )\n            fig_location.update_geos(\n                center={\"lat\": 39.0, \"lon\": 35.0},\n                lataxis_range=[35, 43],\n                lonaxis_range=[25, 45],\n                showland=True,\n                showcountries=True,\n            )\n            fig_location.update_layout(\n                template=\"plotly_dark\",\n                paper_bgcolor=\"rgba(0,0,0,1)\",\n                plot_bgcolor=\"rgba(0,0,0,0)\",\n                font_color=\"#e5edff\"\n            )\n        else:\n            fig_location = px.scatter(\n                x=[0], y=[0], text=[f\"{il} / {ilce}\"],\n                title=\"Lokasyon GÃ¶sterimi\",\n            )\n            fig_location.update_traces(textposition=\"top center\")\n            fig_location.update_xaxes(visible=False)\n            fig_location.update_yaxes(visible=False)\n            fig_location.update_layout(\n                template=\"plotly_dark\",\n                paper_bgcolor=\"rgba(0,0,0,0)\",\n                plot_bgcolor=\"rgba(0,0,0,0)\",\n                font_color=\"#e5edff\"\n            )\n\n    # geÃ§miÅŸ\n    if code not in HISTORY_CODES:\n        HISTORY_CODES.append(code)\n    hist_md = \"### ğŸ” GeÃ§miÅŸ Aramalar\\n\" + \", \".join(HISTORY_CODES)\n\n    return (card_md, ek_md, nf_md, detay_df,\n            explanation_md, fig_years, fig_reasons, fig_location,\n            hist_md, HISTORY_CODES)\n\n# ================== KARAR AÃ‡IKLAMASI ==================\ndef explain_decision(file, cbs_code):\n    if file is None:\n        return \"Ã–nce Excel dosyasÄ±nÄ± yÃ¼kleyin.\"\n    card_md, *_ = analyze_file(file, cbs_code)\n\n    code = clean_str(cbs_code).upper()\n    lines = [f\"### ğŸ“˜ {code} iÃ§in Karar AÃ§Ä±klamasÄ±\\n\"]\n    if \"Karar: YATIRIM\" in card_md:\n        lines.append(\"- Ortalama yÃ¼k yÃ¼ksek veya eski tarihli bir unsur olduÄŸu iÃ§in yatÄ±rÄ±m Ã¶nceliÄŸi Ã¶ne Ã§Ä±kÄ±yor.\")\n        lines.append(\"- 28.01.2009 Ã¶ncesi dÃ¶nemde olmasÄ± ve kesinti profili yatÄ±rÄ±m ihtiyacÄ±nÄ± destekliyor.\")\n    elif \"Karar: OPERASYON\" in card_md:\n        lines.append(\"- Åebeke unsuru gÃ¶rece yeni (2009 sonrasÄ±) kabul ediliyor.\")\n        lines.append(\"- YÃ¼k ve kesinti davranÄ±ÅŸÄ±, operasyonel mÃ¼dahale ile yÃ¶netilebilir seviyede.\")\n        lines.append(\"- Bu nedenle operasyonel aksiyonlar Ã¶nceliklidir.\")\n    else:  # BAKIM\n        lines.append(\"- YÃ¼k seviyesi kritik eÅŸiklerin altÄ±nda.\")\n        lines.append(\"- Kesinti profili, periyodik ve hedefli bakÄ±m ile yÃ¶netilebilir durumda.\")\n        lines.append(\"- Bu nedenle sonuÃ§ *BAKIM* yÃ¶nÃ¼nde; yatÄ±rÄ±m Ã¶nceliÄŸi daha dÃ¼ÅŸÃ¼ktÃ¼r.\")\n    return \"\\n\".join(lines)\n\n# ================== GEÃ‡MÄ°Å KODDAN GÃ–STER ==================\ndef show_from_history(file, history_code):\n    if file is None:\n        return (\"LÃ¼tfen Excel dosyasÄ±nÄ± yÃ¼kleyin.\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n    if not history_code:\n        return (\"LÃ¼tfen geÃ§miÅŸ listeden bir CBS kodu seÃ§in.\", \"\", \"\", pd.DataFrame(),\n                \"\", None, None, None, \"HenÃ¼z kayÄ±t yok.\", HISTORY_CODES)\n    return analyze_file(file, history_code)\n\n# ================== NEON MAVÄ° GLASSMORPHISM TEMA ==================\nCUSTOM_CSS = \"\"\"\n/* Background Gradient + Glow */\nbody {\n    background: radial-gradient(circle at 20% 20%, #4da3ff33 0%, #0a0f1e 60%) !important;\n    font-family: 'Inter', 'Segoe UI', sans-serif !important;\n    color: #e8ecf2 !important;\n}\n\n/* Glassmorphism Panels */\n.gradio-container, .gr-box, .gr-panel {\n    background: rgba(255, 255, 255, 0.04) !important;\n    backdrop-filter: blur(18px) !important;\n    border: 1px solid rgba(255, 255, 255, 0.09) !important;\n    border-radius: 22px !important;\n    box-shadow: 0 0 35px rgba(80, 150, 255, 0.25) !important;\n    padding: 18px !important;\n}\n\n/* Header */\nh1 {\n    font-size: 42px !important;\n    font-weight: 800 !important;\n    text-align: center;\n    color: #d3e9ff !important;\n    letter-spacing: -0.5px;\n    margin-bottom: -5px !important;\n}\nh2, h3 {\n    color: #c7d8f5 !important;\n}\n\n/* Inputs */\ninput, textarea {\n    background: rgba(255,255,255,0.08) !important;\n    border-radius: 14px !important;\n    border: none !important;\n    padding: 12px 14px !important;\n    color: #e7ecf4 !important;\n    font-weight: 500 !important;\n}\n\n/* Buttons (capsule) */\nbutton {\n    background: linear-gradient(135deg, #66b3ff, #3d8bfd) !important;\n    border-radius: 18px !important;\n    color: white !important;\n    border: none !important;\n    font-weight: 700 !important;\n    padding: 12px 18px !important;\n    font-size: 16px !important;\n    transition: 0.15s ease-in-out !important;\n}\nbutton:hover {\n    transform: scale(1.05);\n    box-shadow: 0px 0px 18px rgba(120,180,255,0.55);\n}\n\n/* Dropdowns */\nselect {\n    background: rgba(255,255,255,0.08) !important;\n    color: #e5edff !important;\n    border-radius: 14px !important;\n    padding: 10px !important;\n}\n\n/* Dataframe */\n.gr-dataframe table {\n    background: rgba(255,255,255,0.05) !important;\n    color: #cfe5ff !important;\n}\n\n/* Plots */\n.gr-plot {\n    background: rgba(255,255,255,0.06) !important;\n    border-radius: 20px !important;\n    padding: 10px !important;\n}\n\"\"\"\n\n# ================== GRADIO ARAYÃœZÃœ ==================\nwith gr.Blocks(css=CUSTOM_CSS) as demo:\n    gr.Markdown(\"\"\"\n    <div style='text-align:center; margin-top:20px; margin-bottom:10px'>\n        <h1>Walter Watt X Shenergy<br>YatÄ±rÄ±m BakÄ±m Sorgulama Sistemi</h1>\n        <p style='color:#9fb3ff; font-size:15px; margin-top:4px;'>\n            CBS kodunu gir, sistem karar aÄŸacÄ± ile otomatik yatÄ±rÄ±m / bakÄ±m / operasyon analizini oluÅŸtursun.\n        </p>\n    </div>\n    \"\"\")\n\n    with gr.Row():\n        with gr.Column(scale=1):\n            file_input = gr.File(label=\"Excel YÃ¼kle\", file_types=[\".xlsx\"])\n        with gr.Column(scale=1):\n            cbs_input = gr.Textbox(label=\"CBS Kodu\", placeholder=\"Ã–rn: TAM175TR1P1D\")\n\n    with gr.Row():\n        analyze_btn = gr.Button(\"Analiz Et\")\n        explain_btn = gr.Button(\"Karar AÃ§Ä±klamasÄ±\")\n        history_btn = gr.Button(\"GeÃ§miÅŸ KararÄ± GÃ¶ster\")\n\n    karar_md = gr.Markdown()\n    ek_md = gr.Markdown()\n    nf_md = gr.Markdown()\n\n    detay_tbl = gr.Dataframe(\n        label=\"Kesinti KayÄ±tlarÄ±\",\n        headers=[\"BaÅŸlangÄ±Ã§\",\"BitiÅŸ\",\"SÃ¼re (saat)\",\"Neden\",\"YÃ¼k (%)\",\"Ä°l\",\"Ä°lÃ§e\"],\n        row_count=0, col_count=7\n    )\n\n    explanation_md = gr.Markdown()\n\n    with gr.Row():\n        plot_years = gr.Plot(label=\"YÄ±llara GÃ¶re Kesinti SayÄ±sÄ±\")\n        plot_reasons = gr.Plot(label=\"Kesinti Nedenlerinin DaÄŸÄ±lÄ±mÄ±\")\n\n    with gr.Row():\n        plot_location = gr.Plot(label=\"Lokasyon GÃ¶sterimi\")\n\n    history_md = gr.Markdown()\n    history_dd = gr.Dropdown(label=\"GeÃ§miÅŸ CBS KodlarÄ±\", choices=[], interactive=True)\n\n    # ANALÄ°Z\n    analyze_btn.click(\n        fn=analyze_file,\n        inputs=[file_input, cbs_input],\n        outputs=[\n            karar_md, ek_md, nf_md,\n            detay_tbl,\n            explanation_md,\n            plot_years, plot_reasons, plot_location,\n            history_md, history_dd\n        ]\n    )\n\n    # KARAR AÃ‡IKLAMASI\n    explain_btn.click(\n        fn=explain_decision,\n        inputs=[file_input, cbs_input],\n        outputs=explanation_md\n    )\n\n    # GEÃ‡MÄ°ÅTEN YÃœKLE\n    history_btn.click(\n        fn=show_from_history,\n        inputs=[file_input, history_dd],\n        outputs=[\n            karar_md, ek_md, nf_md,\n            detay_tbl,\n            explanation_md,\n            plot_years, plot_reasons, plot_location,\n            history_md, history_dd\n        ]\n    )\n\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T08:27:14.969036Z","iopub.execute_input":"2025-12-15T08:27:14.969315Z","iopub.status.idle":"2025-12-15T08:27:30.680912Z","shell.execute_reply.started":"2025-12-15T08:27:14.969294Z","shell.execute_reply":"2025-12-15T08:27:30.679957Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://27a2cc42bb0d36ac44.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://27a2cc42bb0d36ac44.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":5}]}